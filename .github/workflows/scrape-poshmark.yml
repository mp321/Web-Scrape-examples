name: Daily Poshmark Scraper

on:
  schedule:
    # This is a cron expression to run the script every day at midnight UTC
    - cron: "0 0 * * *"
  workflow_dispatch:  # Allows manual trigger from GitHub UI

jobs:
  scrape:
    runs-on: ubuntu-latest  # Use the latest Ubuntu environment for the action

    steps:
      # Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v2

      # Set up Python environment
      - name: Set up Python 3.x
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'  # Use Python 3.x version

      # Install dependencies from requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up Google Sheets Credentials
        run: | 
          echo "${{ secrets.SERVICE_ACCOUNT_KEY }}" > /tmp/service_account.json


      #Set up Google Sheets Credentials
      # - name: Set up Google Sheets Credentials
      #   run: echo "${{ secrets.SERVICE_ACCOUNT_KEY }}" > /tmp/service_account.json

      #test debug -delete
      - name: Debug JSON File
        run: cat /tmp/service_account.json
        
      # Run the scraper script
      - name: Run Scraper Script
        run: |
          python poshmark_data_pull.py  
        
      # Optionally, you can print some debug info (useful for troubleshooting)
      - name: Debug Info
        run: |
          python --version
          pip show selenium pandas gspread  # List installed packages

